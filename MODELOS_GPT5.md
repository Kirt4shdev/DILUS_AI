# ü§ñ Configuraci√≥n de Modelos GPT-5

## üìã Resumen

La aplicaci√≥n DILUS_AI est√° configurada para usar los modelos **GPT-5** de OpenAI:

- **gpt-5-mini**: Modelo r√°pido y eficiente para an√°lisis general
- **gpt-5**: Modelo avanzado con capacidades de razonamiento profundo

---

## üîß Modelos Configurados

### gpt-5-mini (GPT-5 Mini)

**Uso:**
- An√°lisis de pliegos t√©cnicos (primera pasada)
- An√°lisis de contratos (primera pasada)
- Generaci√≥n de ofertas comerciales
- Generaci√≥n de documentaci√≥n t√©cnica
- Chat de la B√≥veda

**Caracter√≠sticas:**
- Context window: ~200k tokens
- L√≠mite aplicado en DILUS_AI: 100k tokens (conservador)
- Velocidad: R√°pido
- Costo: M√°s econ√≥mico

### gpt-5 (GPT-5 Standard)

**Uso:**
- Bot√≥n "Repetir con IA Mejorada üîÑ" en an√°lisis de pliegos
- Bot√≥n "Repetir con IA Mejorada üîÑ" en an√°lisis de contratos
- An√°lisis profundo y complejo

**Caracter√≠sticas:**
- Context window: ~200k tokens
- L√≠mite aplicado en DILUS_AI: 20k tokens (conservador debido a l√≠mites de TPM)
- Velocidad: M√°s lento (mayor razonamiento)
- Costo: M√°s costoso

---

## ‚ö†Ô∏è L√≠mites de Tokens

### ¬øPor qu√© l√≠mites tan conservadores?

Los modelos GPT-5 tienen **l√≠mites de TPM (Tokens Por Minuto)** que debemos respetar:

- **gpt-5**: L√≠mites de TPM m√°s estrictos para an√°lisis profundo
- Esto significa que el total de tokens de entrada + salida debe ser gestionado cuidadosamente

Por eso aplicamos:
- **gpt-5-mini**: L√≠mite de 100k tokens de entrada (conservador)
- **gpt-5**: L√≠mite de 20k tokens de entrada (para evitar errores de TPM)

### Sistema Inteligente de Gesti√≥n de Contexto

DILUS_AI decide autom√°ticamente:

1. **Si el documento cabe en el l√≠mite** ‚Üí Env√≠a el texto completo
2. **Si el documento es muy grande** ‚Üí Usa RAG para obtener solo los fragmentos relevantes

Esto garantiza:
- ‚úÖ Mejor precisi√≥n cuando es posible usar texto completo
- ‚úÖ Evitar errores de l√≠mite de tokens
- ‚úÖ Optimizar costos de API

---

## üîë Configuraci√≥n de API Keys

En tu archivo `.env` o `backend/.env`:

```bash
# API Key para gpt-5-mini (an√°lisis general)
OPENAI_API_KEY=sk-proj-...

# API Key para gpt-5 (an√°lisis mejorado)
# Puede ser la misma API key o una diferente
OPENAI_API_KEY_STANDARD=sk-proj-...
```

---

## üìä Capacidades de GPT-5

Los modelos GPT-5 ofrecen mejoras significativas:

### ‚úÖ Caracter√≠sticas principales:
- Soportan `temperature` para controlar creatividad
- Mensajes de `system` role para instrucciones base
- Razonamiento m√°s profundo y coherente
- Mayor capacidad de contexto
- Mejor comprensi√≥n de documentos t√©cnicos

### üîß Par√°metros configurables:
- `temperature`: Control de aleatoriedad (usamos 0.3 por defecto)
- `max_tokens`: Tokens m√°ximos de salida (4k-8k seg√∫n modelo)
- `system` messages: Instrucciones de rol y contexto

---

## üö® Soluci√≥n a Errores Comunes

### Error: "Request too large"

‚ùå **Error:**
```
Request too large for [model] in organization ... on tokens per min (TPM): 
Limit exceeded.
```

‚úÖ **Soluci√≥n aplicada:**
- Uso de modelos `gpt-5-mini` y `gpt-5` oficiales
- L√≠mite de contexto para Mini: 100k tokens
- L√≠mite de contexto para Standard: 20k tokens
- Implementado uso autom√°tico de RAG para documentos grandes

### Error: "Invalid model specified"

Si recibes un error indicando que el modelo no existe:

1. **Verifica tu acceso a la API:**
   - Los modelos GPT-5 pueden requerir acceso especial
   - Consulta tu tier de acceso en: https://platform.openai.com/account/limits

2. **Alternativa temporal:**
   Si no tienes acceso a GPT-5, puedes modificar temporalmente en `backend/services/aiService.js`:

```javascript
// Para gpt-5-mini
model: 'gpt-4o-mini',

// Para gpt-5
model: 'gpt-4o',
```

---

## üìà Monitoreo de Uso

DILUS_AI registra autom√°ticamente en los logs:

```
INFO: Document 123 fits in context, using full text
      { tokens: 12000, model: 'gpt-5-mini' }

INFO: Document 456 too large, using RAG
      { tokens: 95000, model: 'gpt-5' }

INFO: Final context size for analysis
      { tokens: 19500, model: 'gpt-5', documents: 2 }
```

---

## üîÑ Migraci√≥n desde GPT-4

Si estabas usando GPT-4 previamente:

| Antes | Ahora |
|-------|-------|
| `gpt-4o-mini` | `gpt-5-mini` |
| `gpt-4o` | `gpt-5` |
| L√≠mite: 128k tokens | L√≠mite: 20k-100k tokens (conservador) |
| Soporta system messages | ‚úÖ Soporta system messages |

---

## üìö Recursos Adicionales

- [Documentaci√≥n oficial GPT-5](https://openai.com/index/introducing-gpt-5-for-developers)
- [L√≠mites de rate](https://platform.openai.com/account/rate-limits)
- [Gu√≠a de la API](https://platform.openai.com/docs/guides)

---

## ‚úÖ Verificaci√≥n

Para verificar que todo funciona correctamente:

1. ‚úÖ Sube un documento peque√±o (< 10 p√°ginas)
2. ‚úÖ Realiza un an√°lisis con IA normal (gpt-5-mini)
3. ‚úÖ Prueba el bot√≥n "Repetir con IA Mejorada" (gpt-5)
4. ‚úÖ Revisa los logs del backend para ver el uso de tokens

Si todo funciona sin errores de l√≠mite de tokens, ¬°la configuraci√≥n es correcta! üéâ

---

**√öltima actualizaci√≥n:** 6 de noviembre de 2025

