# ğŸ” CÃ³mo Funciona el RAG HÃ­brido - ExplicaciÃ³n Paso a Paso

## ğŸ“š Â¿QuÃ© es RAG HÃ­brido?

El **RAG HÃ­brido** combina **dos tÃ©cnicas de bÃºsqueda** para encontrar los chunks mÃ¡s relevantes:

1. **ğŸ§  BÃºsqueda Vectorial (SemÃ¡ntica)** - Entiende el significado
2. **ğŸ”¤ BÃºsqueda BM25 (Keywords)** - Busca palabras clave

---

## ğŸ¯ Proceso Completo del RAG HÃ­brido

### **FASE 1: Cuando subes un documento**

#### Paso 1: Chunking
```
Documento original â†’  DivisiÃ³n en chunks
                    â†“
[Chunk 1: "Miguel Carrasco es..."]
[Chunk 2: "El vibranium tiene..."]
[Chunk 3: "Para cazar topos..."]
```

#### Paso 2: VectorizaciÃ³n (Embeddings)
Cada chunk se convierte en un **vector de 1536 dimensiones**:
```
Texto: "Miguel Carrasco es el lÃ­der supremo"
         â†“ (OpenAI text-embedding-ada-002)
Vector: [0.123, -0.456, 0.789, ..., 0.234] (1536 nÃºmeros)
```

Este vector representa el **significado semÃ¡ntico** del texto.

#### Paso 3: IndexaciÃ³n de Texto Completo (TSV)
PostgreSQL crea un Ã­ndice de bÃºsqueda por palabras:
```
Texto: "Miguel Carrasco es el lÃ­der supremo"
         â†“ (PostgreSQL Full-Text Search)
TSV: 'miguel':1 'carrasco':2 'lider':4 'supremo':5
```

Esto permite bÃºsqueda rÃ¡pida por **palabras clave exactas**.

#### Paso 4: Guardado en BD
```sql
INSERT INTO embeddings (
  document_id,
  chunk_text,
  chunk_index,
  embedding,      -- Vector de 1536 dimensiones
  tsv,            -- Ãndice de texto completo
  metadata
) VALUES (...);
```

---

### **FASE 2: Cuando haces una pregunta**

Supongamos que preguntas: **"Â¿QuiÃ©n es Miguel Carrasco?"**

#### Paso 1: VectorizaciÃ³n de la Query
```
Query: "Â¿QuiÃ©n es Miguel Carrasco?"
         â†“ (OpenAI text-embedding-ada-002)
Query Vector: [0.135, -0.442, 0.801, ..., 0.221]
```

#### Paso 2: BÃºsqueda Vectorial (Similitud SemÃ¡ntica)
PostgreSQL calcula la **distancia coseno** entre tu query y todos los chunks:

```sql
(1 - (embedding <=> query_vector))::FLOAT AS vector_similarity
```

**Â¿CÃ³mo funciona?**
- `<=>` es el operador de distancia coseno de pgvector
- Compara el vector de tu pregunta con cada chunk
- Resultado: 0.0 (nada similar) a 1.0 (idÃ©ntico)

**Ejemplo de resultados:**
```
Chunk 1: "Miguel Carrasco es el lÃ­der supremo"     â†’ 0.87 (muy similar)
Chunk 2: "El vibranium tiene propiedades mÃ¡gicas"  â†’ 0.34 (poco similar)
Chunk 3: "Para cazar topos necesitas..."           â†’ 0.28 (poco similar)
```

#### Paso 3: BÃºsqueda BM25 (Keywords)
PostgreSQL usa `ts_rank` para buscar **coincidencias de palabras**:

```sql
ts_rank(tsv, plainto_tsquery('spanish', query_text))::FLOAT AS bm25_score
```

**Â¿CÃ³mo funciona?**
- `plainto_tsquery('spanish', ...)` convierte tu pregunta en tÃ©rminos de bÃºsqueda
- `ts_rank` calcula un score basado en:
  - **Frecuencia**: Â¿CuÃ¡ntas veces aparece la palabra?
  - **PosiciÃ³n**: Â¿DÃ³nde aparece? (al inicio es mejor)
  - **Rareza**: Palabras raras valen mÃ¡s que comunes

**Ejemplo de resultados:**
```
Query procesada: 'quien' 'miguel' 'carrasco'

Chunk 1: "Miguel Carrasco es el lÃ­der supremo"
  - Tiene "miguel" y "carrasco" âœ…
  - BM25 Score: 0.45

Chunk 2: "El vibranium tiene propiedades mÃ¡gicas"
  - No tiene ninguna palabra âŒ
  - BM25 Score: 0.0

Chunk 3: "Para cazar topos necesitas..."
  - No tiene ninguna palabra âŒ
  - BM25 Score: 0.0
```

#### Paso 4: CÃ¡lculo del Score HÃ­brido
AquÃ­ viene la **magia** ğŸ©:

```sql
hybrid_score = (vector_similarity * vector_weight) + (bm25_score * bm25_weight)
```

Con los pesos configurables (por defecto: 0.6 vectorial, 0.4 BM25):

```
Chunk 1:
  vector_similarity: 0.87
  bm25_score: 0.45
  hybrid_score = (0.87 * 0.6) + (0.45 * 0.4) = 0.522 + 0.180 = 0.702 âœ…

Chunk 2:
  vector_similarity: 0.34
  bm25_score: 0.0
  hybrid_score = (0.34 * 0.6) + (0.0 * 0.4) = 0.204 + 0.0 = 0.204 âŒ

Chunk 3:
  vector_similarity: 0.28
  bm25_score: 0.0
  hybrid_score = (0.28 * 0.6) + (0.0 * 0.4) = 0.168 + 0.0 = 0.168 âŒ
```

#### Paso 5: Ordenamiento y Filtrado
```sql
ORDER BY hybrid_score DESC
LIMIT top_k
```

Los chunks se ordenan por score hÃ­brido y se seleccionan los mejores.

#### Paso 6: Filtros de Threshold
DespuÃ©s de obtener los resultados, se aplican filtros:

```javascript
filteredResults = results.filter(chunk => 
  chunk.vector_similarity >= min_similarity || 
  chunk.hybrid_score >= min_hybrid_score
);
```

**LÃ³gica del filtro (OR):**
- Si `vector_similarity >= 0.3` â†’ âœ… Pasa (es semÃ¡nticamente relevante)
- O si `hybrid_score >= 0.25` â†’ âœ… Pasa (es relevante en general)
- Si ninguno â†’ âŒ Se descarta

---

## ğŸ›ï¸ Ajustes de Pesos

### **MÃ¡s peso a Vectorial (SemÃ¡ntico)**
```
vector_weight = 0.8, bm25_weight = 0.2
```
**Mejor para:**
- Preguntas conceptuales: "Â¿CuÃ¡l es el propÃ³sito de X?"
- SinÃ³nimos y parÃ¡frasis
- ComprensiÃ³n de contexto

### **MÃ¡s peso a BM25 (Keywords)**
```
vector_weight = 0.4, bm25_weight = 0.6
```
**Mejor para:**
- Nombres propios especÃ­ficos
- TÃ©rminos tÃ©cnicos exactos
- BÃºsquedas literales

### **Equilibrado (Por defecto)**
```
vector_weight = 0.6, bm25_weight = 0.4
```
**Mejor para:**
- Uso general
- Balance entre precisiÃ³n y recall

---

## ğŸ“Š Ejemplo Completo Real

### Pregunta: "Â¿CÃ³mo se caza un topo?"

#### 1. VectorizaciÃ³n
```
Query Vector: [0.234, -0.567, 0.891, ...]
```

#### 2. BÃºsqueda en BD
```sql
SELECT 
  chunk_text,
  (1 - (embedding <=> query_vector)) AS vector_similarity,
  ts_rank(tsv, plainto_tsquery('spanish', 'caza topo')) AS bm25_score,
  ((1 - (embedding <=> query_vector)) * 0.6 + 
   ts_rank(tsv, ...) * 0.4) AS hybrid_score
FROM embeddings
ORDER BY hybrid_score DESC
LIMIT 5;
```

#### 3. Resultados
```
Chunk A: "Para cazar un topo necesitas una pala y paciencia..."
  - vector_similarity: 0.75 (entiende que habla de cazar topos)
  - bm25_score: 0.62 (contiene "caza" y "topo")
  - hybrid_score: 0.75 * 0.6 + 0.62 * 0.4 = 0.698 ğŸ¥‡

Chunk B: "Los topos son animales subterrÃ¡neos..."
  - vector_similarity: 0.58 (habla de topos pero no de cazar)
  - bm25_score: 0.31 (solo contiene "topo")
  - hybrid_score: 0.58 * 0.6 + 0.31 * 0.4 = 0.472 ğŸ¥ˆ

Chunk C: "La caza deportiva requiere licencia..."
  - vector_similarity: 0.42 (habla de caza pero no de topos)
  - bm25_score: 0.35 (solo contiene "caza")
  - hybrid_score: 0.42 * 0.6 + 0.35 * 0.4 = 0.392 ğŸ¥‰
```

#### 4. Filtrado
```
min_similarity = 0.3
min_hybrid_score = 0.25

Chunk A: 0.75 >= 0.3 âœ… (pasa)
Chunk B: 0.58 >= 0.3 âœ… (pasa)
Chunk C: 0.42 >= 0.3 âœ… (pasa)
```

#### 5. Resultado Final
Se envÃ­an los chunks A y B (top 2) al LLM para generar la respuesta.

---

## ğŸ’¡ Ventajas del Sistema HÃ­brido

| Aspecto | Solo Vectorial | Solo BM25 | **HÃ­brido** |
|---------|---------------|-----------|-------------|
| SinÃ³nimos | âœ… Excelente | âŒ No detecta | âœ… Excelente |
| Nombres propios | ğŸŸ¡ Variable | âœ… Excelente | âœ… Excelente |
| Contexto | âœ… Excelente | âŒ No entiende | âœ… Excelente |
| Palabras raras | ğŸŸ¡ Variable | âœ… Excelente | âœ… Excelente |
| PrecisiÃ³n | ğŸŸ¡ Buena | ğŸŸ¡ Buena | âœ… **Muy buena** |
| Recall | âœ… Alto | ğŸŸ¡ Medio | âœ… **Muy alto** |

---

## ğŸ”§ ConfiguraciÃ³n Actual en tu Sistema

Todos estos parÃ¡metros son ajustables desde **Admin Panel â†’ Control del RAG**:

- **chunk_size**: 1000 caracteres
- **chunk_overlap**: 200 caracteres
- **chunking_method**: fixed / sentence / **paragraph** â­ (Â¡ya funciona!)
- **top_k**: 5 chunks
- **min_similarity**: 0.3 (threshold vectorial)
- **min_hybrid_score**: 0.25 (threshold hÃ­brido)
- **vector_weight**: 0.6 (60% peso semÃ¡ntico)
- **bm25_weight**: 0.4 (40% peso keywords)

---

## ğŸ“ Resumen Ejecutivo

1. **Embeddings (Vectorial)** = Entiende el **significado**
2. **BM25 (Keywords)** = Busca **palabras exactas**
3. **HÃ­brido** = Combina ambos con **pesos configurables**
4. **Resultado** = Chunks mÃ¡s relevantes tanto semÃ¡nticamente como por contenido literal

**Â¡Lo mejor de dos mundos!** ğŸŒğŸŒ

